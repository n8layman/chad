#' Explain Last Error Using OpenAI
#'
#' @author Nathan C. Layman
#'
#' @param model A string specifying the type of model to be used, default is "gpt-4".
#' @param prompt A string defining the prompt for the explanation. The default explains a provided error using a stack trace.
#' @param show_trace A boolean defining if the function should print the trace from the last error, default is False.
#' @param show_trace_JSON A boolean defining if the function should print the JSON representation of the trace from the last error, default is False.
#'
#' @return This function primarily returns its results to console via message(). It does not return anything to the global scope unless assigned to a variable. In that case it returns a string explaining the nature of the provided error. It includes an error message and an explanation generated by the specified model.
#'
#' @note This function relies on enriched errors provided by the rlang package. If such an error is not available it will attach rlang and prompt the user to rerun their command to generate an enriched error.
#'
#' @examples
#' \dontrun{
#'   library(rlang)
#'   global_entrace()
#'   # Run a command that produces an error
#'   explain_last_error(show_trace = T, show_trace_JSON = T)
#' }
#'
#' @export explain_last_error
explain_last_error <- function(model = "gpt-4",
                               prompt = "Give an explanation for the following error in the R programing language and use the provided stack trace to aid the user in resolving the problem. Do not ask for code snippets or any further information.",
                               show_trace = F,
                               show_trace_JSON = F,
                               code = NULL) {

  if(!nzchar(Sys.getenv("OPENAI_API_KEY"))) {
    warning(cli::cli_text("OpenAI API key not found! To remedy:\n
            \t 1. Visit {.url https://platform.openai.com/api-keys} to create an account and request an API key\n
            \t 2. Run `Sys.setenv(OPENAI_API_KEY = 'sk-xxxx')` where 'sk-xxx' is the API key provided by OpenAI or add your key to your .env file or .RProfile \n
            \t 3. Try `explain_last_error()` again\n"))
    return()
  }

  e <- tryCatch({
    rlang::last_error()
  },
  error = function(e) {
    message("This function depends on rlang enriched errors. Please run `rlang::global_entrace()` or add it to your .RProfile before running whatever code generated the error you want to explain. Loading it now.`\n")
    rlang::global_entrace()
    return()
  })

  if(show_trace == T) {
    cat("Trace:\n")
    print(e$trace)
  }

  trace <- serialize_trace(e)

  if(show_trace_JSON == T) {
    message(paste("\nTrace JSON:", trace |> jsonlite::prettify()))
  }

  messages <-
    list(
      list(
        "role" = "system",
        "content" = prompt
      ),
      list(
        "role" = "user",
        "content" = paste("error:", e$message)
      ),
      list(
        "role" = "user",
        "content" = paste("JSON object representing the stack trace:", trace)
      )
    )

  if(!is.null(code)) {
    # Deparse the function code into a character vector
    code_string <- deparse(code) |> paste(collapse = "\n")

    messages <- c(messages, list(list("role" = "user", "content" = glue::glue("The code that produced the error was:
    {code_string}"))))
  }

  err <- openai::create_chat_completion(
    model = model,
    messages = messages)['choices'][[1]]$message.content

  err <- paste("\nError:", e$message, "\n\nExplanation:", err |> unlist())

  message(err)
  invisible(err)
}
